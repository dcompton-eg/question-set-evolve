# Interview Question Set Design Prompt

## Role Being Hired For
Senior Go (Golang) Backend Engineer

## Interview Context
**This is a recruiter phone screen.**
- Questions will be asked by a non-technical recruiter reading from a script
- Questions must be simple to read aloud and understand
- 10-minute phone screen
- Scoring will be done by LLM-as-judge from the transcript

## Candidate Level
Senior (5+ years Go experience, 7+ years total engineering experience)

## What We Want to Learn
- Whether the candidate has genuine hands-on Go experience
- Basic understanding of Go's key concepts (concurrency, error handling)
- Production experience with Go services
- Ability to explain technical concepts clearly

## Question Requirements
- Exactly 3 scripted questions
- No follow-up questions (recruiter reads questions as-is)
- Questions must be easy for a non-technical person to read aloud
- Questions should allow candidates to demonstrate real experience
- Avoid jargon-heavy questions that are hard to pronounce or understand
- Questions should fit within ~10 minutes total (about 3 minutes per question)
- Question should require an appropriate level of technical detail for the time limit
- **Questions must collectively cover: (1) hands-on Go project experience, (2) Go-specific concepts (concurrency OR error handling), (3) production deployment/operational considerations**

## Fairness Guardrails
To ensure equitable assessment across diverse backgrounds and career paths:
- **Avoid seniority-gating language** that privileges certain company sizes or roles. Use "service" instead of "microservice," "task" instead of "distributed system"
- **Avoid region/industry assumptions**. Don't assume candidates worked at specific companies or with specific frameworks (e.g., Kubernetes, Datadog). Use neutral language like "monitoring tool" or "deployment system"
- **Avoid implicit credential requirements**. Don't require candidates to have worked at FAANG companies or on "high scale" systems. A 1K RPS service demonstrates the same technical capability as a 1M RPS service
- **Ask for "an example you remember"** rather than "your most impressive project" to reduce anxiety and cultural bias
- **Accept equivalent technologies**. A candidate who handled errors with a custom wrapper is as competent as one using standard error wrapping packages
- **Recognize diverse solution paths**. A candidate who used mutexes + channels is demonstrating the same concurrency understanding as one who used channels alone

## Red Flags (for LLM scoring rubric)
- Cannot explain what they've built with Go
- Vague or generic answers that could apply to any language
- No mention of real projects or production experience
- Cannot articulate basic Go concepts in simple terms
- Answers that describe Go features without explaining why they matter
- No discussion of trade-offs or constraints

## Green Flags (for LLM scoring rubric)
- Specific examples from real projects with measurable context (team size, scale, timeline)
- Clear explanation of Go-specific features and why they matter
- Demonstrates understanding of Go's strengths and trade-offs
- Can explain technical concepts in accessible language
- Mentions concrete challenges encountered and how they were solved
- Discusses operational aspects (monitoring, debugging, deployment)

## Output Format
Provide a question set with:
- Exactly 3 clear, scripted questions
- Questions phrased for a non-technical recruiter to read aloud
- Time allocation (should sum to ~10 minutes)
- Explicit coverage map showing which question addresses which learning goal
- What to look for in answers (for LLM scoring)

The LLM scoring rubric should include:
- What a strong answer looks like
- What a weak answer looks like
- Specific signals to listen for
- **Transcript-matchable indicators** (concrete phrases, patterns, or details that signal competence level)
- **For each question: minimum viable evidence of competence** (what must be present for a passing score)

## Question Design Guidance for Depth and Layering

To ensure questions elicit substantive responses within the 3-minute window:
- **Question 1 (Project Experience)**: Ask for a specific project, then ask them to describe ONE key technical decision or challenge they faced. This creates natural depth without requiring follow-ups.
  - Example structure: "Tell me about a Go backend project you built or maintained. What was the biggest technical challenge you had to solve, and how did you approach it?"
  - Fairness note: Accept any project type (REST API, worker, batch job, microservice, etc.) and any scale (small internal tool to large-scale system). The technical challenge is what matters, not the size.
  
- **Question 2 (Go Concepts)**: Ask them to explain a Go-specific feature in context of a real problem they solved, not in abstract.
  - Example structure: "Go has some unique features for handling [concurrency/errors]. Tell me about a time when you used [goroutines/channels/error handling pattern] to solve a problem in production. What would have been harder or different if you were using a different language?"
  - Fairness note: Accept any valid Go concurrency or error handling approach (goroutines, channels, mutexes, context cancellation, error wrapping, custom error types, etc.). All demonstrate competence.
  
- **Question 3 (Production/Operations)**: Ask about a specific operational challenge (not just deployment), forcing them to discuss constraints and trade-offs.
  - Example structure: "Tell me about a time when a Go service you built caused an operational problem in productionâ€”maybe a performance issue, memory leak, or unexpected behavior. How did you debug it and what did you learn?"
  - Fairness note: Accept any operational problem (small or large). A candidate who debugged a single-threaded memory issue demonstrates the same debugging competence as one who debugged a distributed system race condition.

These structures naturally prompt candidates to provide specificity, context, and depth without requiring follow-up questions.